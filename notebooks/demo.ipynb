{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "base_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(base_dir)\n",
    "\n",
    "from src.experiments import cGANCloudTOPtoRGB, Logger\n",
    "from src.models import Unet, PatchGAN\n",
    "from src.datasets import CloudTOPtoRGBDataset\n",
    "from src.utils import load_yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the session global variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to configuration file\n",
    "cfg_path = '../config/dummy.yaml'\n",
    "\n",
    "# Path to experiment outputs directory\n",
    "output_dir = 'sandbox/'\n",
    "\n",
    "# Id of GPU on which computation will take place - if no GPU, will go on CPU by default\n",
    "gpu_id = 0\n",
    "\n",
    "# Global random seed to set for reproducibility\n",
    "seed = 73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load experiment configuration file\n",
    "\n",
    "Everything we need to setup the experiment is contained in this configuration file that we'll be using throughout this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_yaml(cfg_path)\n",
    "# cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define logger to get some outputs during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.experiments.utils.loggers.Logger at 0x12de57438>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = Logger(save_dir=os.path.dirname(output_dir),\n",
    "                name=os.path.basename(output_dir))\n",
    "logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define an utility which will save model weights checkpoint for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint at 0x12de57208>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint = pl.callbacks.ModelCheckpoint(**cfg['model_checkpoint'])\n",
    "model_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, don't forget to seed the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Here we're going to define instance for the dataset, Unet and discriminator for the GANs training, and it's as simple as :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Unet.build(cfg['model']['generator'])\n",
    "discriminator = PatchGAN.build(cfg['model']['discriminator'])\n",
    "dataset = CloudTOPtoRGBDataset.build(cfg['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run those if you want to look at what the models looks like\n",
    "# print(generator)\n",
    "# print(discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now let's encapsulate all these things into one single `experiment` instance that specifies how training should be performed__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = cGANCloudTOPtoRGB(generator=generator,\n",
    "                               discriminator=discriminator,\n",
    "                               dataset=dataset,\n",
    "                               split=list(cfg['dataset']['split'].values()),\n",
    "                               optimizer_kwargs=cfg['optimizer'],\n",
    "                               lr_scheduler_kwargs=cfg['lr_scheduler'],\n",
    "                               dataloader_kwargs=cfg['dataset']['dataloader'],\n",
    "                               supervision_weight_l1=cfg['experiment']['supervision_weight_l1'],\n",
    "                               supervision_weight_ssim=cfg['experiment']['supervision_weight_ssim'],\n",
    "                               seed=cfg['experiment']['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Training\n",
    "\n",
    "__This is the final step, we're going to feed our experiment to a `Trainer` that will run it__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "No environment variable for node rank defined. Set as 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.trainer.trainer.Trainer at 0x1295f9588>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(logger=logger,\n",
    "                     checkpoint_callback=model_checkpoint,\n",
    "                     precision=cfg['experiment']['precision'],\n",
    "                     max_epochs=cfg['experiment']['max_epochs'],\n",
    "                     gpus=gpu_id)\n",
    "trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Execute training__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                                    | Type            | Params\n",
      "------------------------------------------------------------------------\n",
      "0  | model                                   | Unet            | 16 M  \n",
      "1  | model.encoder                           | Encoder         | 11 M  \n",
      "2  | model.encoder.encoding_layers           | Sequential      | 11 M  \n",
      "3  | model.encoder.encoding_layers.0         | Conv2d          | 3 K   \n",
      "4  | model.encoder.encoding_layers.0.conv    | Conv2d          | 3 K   \n",
      "5  | model.encoder.encoding_layers.1         | Conv2d          | 131 K \n",
      "6  | model.encoder.encoding_layers.1.conv    | Conv2d          | 131 K \n",
      "7  | model.encoder.encoding_layers.1.bn      | BatchNorm2d     | 256   \n",
      "8  | model.encoder.encoding_layers.1.relu    | PReLU           | 1     \n",
      "9  | model.encoder.encoding_layers.2         | Conv2d          | 525 K \n",
      "10 | model.encoder.encoding_layers.2.conv    | Conv2d          | 524 K \n",
      "11 | model.encoder.encoding_layers.2.bn      | BatchNorm2d     | 512   \n",
      "12 | model.encoder.encoding_layers.2.relu    | PReLU           | 1     \n",
      "13 | model.encoder.encoding_layers.3         | Conv2d          | 2 M   \n",
      "14 | model.encoder.encoding_layers.3.conv    | Conv2d          | 2 M   \n",
      "15 | model.encoder.encoding_layers.3.bn      | BatchNorm2d     | 1 K   \n",
      "16 | model.encoder.encoding_layers.3.relu    | PReLU           | 1     \n",
      "17 | model.encoder.encoding_layers.4         | Conv2d          | 8 M   \n",
      "18 | model.encoder.encoding_layers.4.conv    | Conv2d          | 8 M   \n",
      "19 | model.encoder.encoding_layers.4.bn      | BatchNorm2d     | 2 K   \n",
      "20 | model.encoder.encoding_layers.4.relu    | PReLU           | 1     \n",
      "21 | model.decoder                           | Decoder         | 5 M   \n",
      "22 | model.decoder.decoding_layers           | Sequential      | 5 M   \n",
      "23 | model.decoder.decoding_layers.0         | ConvTranspose2d | 2 M   \n",
      "24 | model.decoder.decoding_layers.0.conv    | ConvTranspose2d | 2 M   \n",
      "25 | model.decoder.decoding_layers.0.bn      | BatchNorm2d     | 1 K   \n",
      "26 | model.decoder.decoding_layers.0.dropout | Dropout         | 0     \n",
      "27 | model.decoder.decoding_layers.0.relu    | PReLU           | 1     \n",
      "28 | model.decoder.decoding_layers.1         | ConvTranspose2d | 2 M   \n",
      "29 | model.decoder.decoding_layers.1.conv    | ConvTranspose2d | 2 M   \n",
      "30 | model.decoder.decoding_layers.1.bn      | BatchNorm2d     | 512   \n",
      "31 | model.decoder.decoding_layers.1.dropout | Dropout         | 0     \n",
      "32 | model.decoder.decoding_layers.1.relu    | PReLU           | 1     \n",
      "33 | model.decoder.decoding_layers.2         | ConvTranspose2d | 590 K \n",
      "34 | model.decoder.decoding_layers.2.conv    | ConvTranspose2d | 589 K \n",
      "35 | model.decoder.decoding_layers.2.bn      | BatchNorm2d     | 256   \n",
      "36 | model.decoder.decoding_layers.2.relu    | PReLU           | 1     \n",
      "37 | model.decoder.decoding_layers.3         | ConvTranspose2d | 147 K \n",
      "38 | model.decoder.decoding_layers.3.conv    | ConvTranspose2d | 147 K \n",
      "39 | model.decoder.decoding_layers.3.bn      | BatchNorm2d     | 128   \n",
      "40 | model.decoder.decoding_layers.3.relu    | PReLU           | 1     \n",
      "41 | model.decoder.decoding_layers.4         | ConvTranspose2d | 73 K  \n",
      "42 | model.decoder.decoding_layers.4.conv    | ConvTranspose2d | 73 K  \n",
      "43 | model.output_layer                      | Conv2d          | 1 K   \n",
      "44 | model.output_layer.conv                 | Conv2d          | 1 K   \n",
      "45 | criterion                               | BCELoss         | 0     \n",
      "46 | discriminator                           | PatchGAN        | 6 M   \n",
      "47 | discriminator.conv_layers               | Sequential      | 6 M   \n",
      "48 | discriminator.conv_layers.0             | Conv2d          | 12 K  \n",
      "49 | discriminator.conv_layers.0.conv        | Conv2d          | 12 K  \n",
      "50 | discriminator.conv_layers.0.relu        | LeakyReLU       | 0     \n",
      "51 | discriminator.conv_layers.1             | Conv2d          | 525 K \n",
      "52 | discriminator.conv_layers.1.conv        | Conv2d          | 524 K \n",
      "53 | discriminator.conv_layers.1.bn          | BatchNorm2d     | 512   \n",
      "54 | discriminator.conv_layers.1.relu        | LeakyReLU       | 0     \n",
      "55 | discriminator.conv_layers.2             | Conv2d          | 2 M   \n",
      "56 | discriminator.conv_layers.2.conv        | Conv2d          | 2 M   \n",
      "57 | discriminator.conv_layers.2.bn          | BatchNorm2d     | 1 K   \n",
      "58 | discriminator.conv_layers.2.relu        | LeakyReLU       | 0     \n",
      "59 | discriminator.conv_layers.3             | Conv2d          | 4 M   \n",
      "60 | discriminator.conv_layers.3.conv        | Conv2d          | 4 M   \n",
      "61 | discriminator.conv_layers.3.bn          | BatchNorm2d     | 1 K   \n",
      "62 | discriminator.conv_layers.3.relu        | LeakyReLU       | 0     \n",
      "63 | discriminator.conv_layers.4             | Conv2d          | 8 K   \n",
      "64 | discriminator.conv_layers.4.conv        | Conv2d          | 8 K   \n",
      "65 | discriminator.sigmoid                   | Sigmoid         | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dieze/Documents/Programming/venv/torch-3.6/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bc47df3033485490a8c63b98240753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While training you model, you can visualize output logs with `tensorboard`. \n",
    "\n",
    "To do so, go to your previously defined `output_dir` and run `tensorboard --logdir=output_dir --port=6008`\n",
    "\n",
    "Then go to your browser and type `localhost:6008`, it might take some time to load"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
